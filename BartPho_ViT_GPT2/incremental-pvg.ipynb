{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11334502,"sourceType":"datasetVersion","datasetId":6723117},{"sourceId":11337142,"sourceType":"datasetVersion","datasetId":7085417,"isSourceIdPinned":true},{"sourceId":331865,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":277580,"modelId":298468},{"sourceId":374794,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":307843,"modelId":328293}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mlflow pyvi minio -q\n!pip install hf_xet -q\n\nimport mlflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:36:23.598453Z","iopub.execute_input":"2025-05-26T15:36:23.598634Z","iopub.status.idle":"2025-05-26T15:36:47.281552Z","shell.execute_reply.started":"2025-05-26T15:36:23.598617Z","shell.execute_reply":"2025-05-26T15:36:47.280917Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.5/720.5 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"mlflow.set_tracking_uri(\"http://36.50.135.226:7893/\")\n\n# from mlflow.tracking import MlflowClient\n\n# client = MlflowClient()\n# client.restore_experiment(experiment_id=\"2\")\n\nmlflow.set_experiment(experiment_id=\"10\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:36:47.283644Z","iopub.execute_input":"2025-05-26T15:36:47.284109Z","iopub.status.idle":"2025-05-26T15:36:47.756687Z","shell.execute_reply.started":"2025-05-26T15:36:47.284089Z","shell.execute_reply":"2025-05-26T15:36:47.755401Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<Experiment: artifact_location='s3://mlflow/6', creation_time=1745743711248, experiment_id='10', last_update_time=1745743711248, lifecycle_stage='active', name='ImageCaption_TPC37k_BartPho-ViT-GPT2_LoRALayerFT', tags={}>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\n\nos.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://36.50.135.226:9000\"\nos.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:36:47.757764Z","iopub.execute_input":"2025-05-26T15:36:47.758738Z","iopub.status.idle":"2025-05-26T15:36:47.763624Z","shell.execute_reply.started":"2025-05-26T15:36:47.758705Z","shell.execute_reply":"2025-05-26T15:36:47.762647Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# MinIO","metadata":{}},{"cell_type":"code","source":"from minio import Minio\nfrom minio.error import S3Error\nimport glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:36:47.764566Z","iopub.execute_input":"2025-05-26T15:36:47.765243Z","iopub.status.idle":"2025-05-26T15:36:48.288263Z","shell.execute_reply.started":"2025-05-26T15:36:47.765213Z","shell.execute_reply":"2025-05-26T15:36:48.287610Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n\nimport transformers\nfrom transformers import VisionEncoderDecoderModel, ViTImageProcessor\nimport torch\nfrom PIL import Image\nimport torch.nn as nn\nimport cv2\nimport torchvision\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport requests\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom transformers import ViTForImageClassification, ViTImageProcessor\nfrom collections import OrderedDict\nfrom transformers import GPT2Config, GPT2LMHeadModel\nimport mlflow\nfrom mlflow.models import infer_signature\nimport mlflow.pytorch\nimport re\nfrom pyvi import ViTokenizer\nfrom torch.optim import AdamW\nfrom datetime import datetime\nimport json\nimport pickle\nfrom io import BytesIO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:36:48.289121Z","iopub.execute_input":"2025-05-26T15:36:48.289321Z","iopub.status.idle":"2025-05-26T15:37:30.453045Z","shell.execute_reply.started":"2025-05-26T15:36:48.289304Z","shell.execute_reply":"2025-05-26T15:37:30.452367Z"}},"outputs":[{"name":"stderr","text":"2025-05-26 15:37:10.723213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748273831.138258      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748273831.277461      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# 1. Chuẩn bị file thư viện","metadata":{}},{"cell_type":"code","source":"pip freeze > requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:37:30.453889Z","iopub.execute_input":"2025-05-26T15:37:30.454435Z","iopub.status.idle":"2025-05-26T15:37:32.368899Z","shell.execute_reply.started":"2025-05-26T15:37:30.454404Z","shell.execute_reply":"2025-05-26T15:37:32.367704Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"with open(\"requirements.txt\") as f:\n    pip_reqs = [line.strip() for line in f if line.strip()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:37:32.372168Z","iopub.execute_input":"2025-05-26T15:37:32.372446Z","iopub.status.idle":"2025-05-26T15:37:32.377904Z","shell.execute_reply.started":"2025-05-26T15:37:32.372420Z","shell.execute_reply":"2025-05-26T15:37:32.377259Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# 2. Load data","metadata":{}},{"cell_type":"markdown","source":"## API Data","metadata":{}},{"cell_type":"code","source":"# 1. Gửi GET request đến API metadata\nurl = \"http://36.50.135.226/api/v1/metadata/encoded-data\"\nheaders = {\"accept\": \"application/json\"}\n\nresponse = requests.get(url, headers=headers)\n\n# 2. Kiểm tra phản hồi\nif response.status_code == 200:\n    data = response.json()\n    object_keys = data.get(\"object_keys\", [])\n\n    def extract_timestamp(key):\n        match = re.search(r\"encoded_data_(\\d{14})\\.pkl\", key)\n        if match:\n            return datetime.strptime(match.group(1), \"%Y%m%d%H%M%S\")\n        return None\n\n    if object_keys:\n        base_url = \"http://160.191.244.13:9000/lakehouse/\"\n        all_pkl_data = []  # Biến chứa toàn bộ dữ liệu\n\n        for key in sorted(object_keys, key=extract_timestamp):\n            file_url = base_url + key\n            file_response = requests.get(file_url)\n\n            if file_response.status_code == 200:\n                try:\n                    file_bytes = BytesIO(file_response.content)\n                    pkl_data = pickle.load(file_bytes)\n\n                    # Gộp dữ liệu\n                    if isinstance(pkl_data, list):\n                        all_pkl_data.extend(pkl_data)\n                    elif isinstance(pkl_data, dict):\n                        all_pkl_data.append(pkl_data)\n                    else:\n                        all_pkl_data.append(pkl_data)\n\n                    print(f\"✅ Đã xử lý: {key}\")\n                except Exception as e:\n                    print(f\"⚠️ Lỗi đọc file {key}: {e}\")\n            else:\n                print(f\"❌ Không thể tải file: {key}\")\n        \n        # ✅ In ra tổng số phần tử đã gộp\n        print(f\"\\n📦 Tổng số đối tượng đã gộp: {len(all_pkl_data)}\")\n    else:\n        print(\"Không có object_keys nào trong dữ liệu.\")\nelse:\n    print(\"Lỗi khi gọi API:\", response.status_code)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:37:44.968313Z","iopub.execute_input":"2025-05-26T15:37:44.968615Z","iopub.status.idle":"2025-05-26T15:54:11.988974Z","shell.execute_reply.started":"2025-05-26T15:37:44.968584Z","shell.execute_reply":"2025-05-26T15:54:11.988159Z"}},"outputs":[{"name":"stdout","text":"✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145536.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145620.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145657.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145708.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145719.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145731.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145744.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145755.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145809.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145821.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145832.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145846.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145859.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145913.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145925.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145938.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524145952.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150005.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150016.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150027.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150039.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150051.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150104.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150115.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150130.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150143.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150156.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150209.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150223.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150236.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150250.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150305.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150319.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150331.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150343.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150356.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150408.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150419.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150431.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150443.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150456.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150510.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150522.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150536.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150549.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150602.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150617.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150630.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150643.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150655.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150708.pkl\n✅ Đã xử lý: imcp/encoded-data/2025-05-24/encoded_data_20250524150719.pkl\n\n📦 Tổng số đối tượng đã gộp: 2576\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(len(all_pkl_data))\nprint(all_pkl_data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:54:11.989753Z","iopub.execute_input":"2025-05-26T15:54:11.990012Z","iopub.status.idle":"2025-05-26T15:54:11.998143Z","shell.execute_reply.started":"2025-05-26T15:54:11.989993Z","shell.execute_reply":"2025-05-26T15:54:11.997158Z"}},"outputs":[{"name":"stdout","text":"2576\n{'image_url': 'http://160.191.244.13:9000/lakehouse/imcp/augmented-data/2025-05-24/6e0a007b66b69f7c9aacb9b46606f0ed.jpg', 'pixel_values': tensor([[[[-0.9059, -0.7725, -0.7333,  ...,  0.0275, -0.0039, -0.0118],\n          [-0.8196, -0.6471, -0.5843,  ...,  0.0196,  0.0039, -0.0196],\n          [-0.6392, -0.6706, -0.6549,  ..., -0.0118, -0.0275, -0.0431],\n          ...,\n          [-0.2627, -0.2471, -0.2549,  ...,  0.1216,  0.2627,  0.2471],\n          [-0.2549, -0.2314, -0.2392,  ...,  0.4275,  0.4745,  0.3804],\n          [-0.2549, -0.2314, -0.2235,  ..., -0.0431, -0.0353, -0.0353]],\n\n         [[-0.8902, -0.7490, -0.7098,  ..., -0.3176, -0.3412, -0.3647],\n          [-0.8039, -0.6235, -0.5608,  ..., -0.3412, -0.3569, -0.3804],\n          [-0.6157, -0.6549, -0.6314,  ..., -0.3569, -0.3647, -0.3882],\n          ...,\n          [-0.4745, -0.4745, -0.4824,  ..., -0.0667,  0.0745,  0.0745],\n          [-0.4824, -0.4824, -0.4980,  ...,  0.2863,  0.3412,  0.2627],\n          [-0.4745, -0.4902, -0.4902,  ..., -0.2157, -0.2000, -0.2078]],\n\n         [[-0.9765, -0.8745, -0.8745,  ..., -0.7647, -0.7725, -0.7725],\n          [-0.8824, -0.7569, -0.7333,  ..., -0.7647, -0.7647, -0.7882],\n          [-0.7176, -0.7882, -0.8039,  ..., -0.7569, -0.7647, -0.7961],\n          ...,\n          [-0.6941, -0.6784, -0.6706,  ..., -0.1686,  0.0039,  0.0039],\n          [-0.6941, -0.6627, -0.6627,  ...,  0.2784,  0.3569,  0.2627],\n          [-0.6863, -0.6627, -0.6392,  ..., -0.2941, -0.2941, -0.3412]]]]), 'input_ids': tensor([[   0, 7069,  140, 1867,  109,    4,  715,  448,  330,    5,  105, 2786,\n           52,  132,    5,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import random\n\n# Giả sử all_pkl_data là một list chứa toàn bộ dữ liệu\nprint(f\"Tổng số dữ liệu: {len(all_pkl_data)}\")  # 2576\n\n# 1. Shuffle để ngẫu nhiên hóa thứ tự (nếu cần)\nrandom.shuffle(all_pkl_data)\n\n# 2. Tính số lượng phần tử cho tập train\ntrain_size = int(0.8 * len(all_pkl_data))  # 80%\n\n# 3. Chia dữ liệu\ntrain_pkl_data = all_pkl_data[:train_size]\ntest_pkl_data = all_pkl_data[train_size:]\n\n# 4. In kiểm tra\nprint(f\"Số lượng train: {len(train_pkl_data)}\")  # ~2060\nprint(f\"Số lượng test: {len(test_pkl_data)}\")    # ~516\n\n# ✅ In mẫu một phần tử\nprint(\"📄 Mẫu train:\")\nprint(train_pkl_data[0])\nprint(\"📄 Mẫu test:\")\nprint(test_pkl_data[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T15:59:57.425827Z","iopub.execute_input":"2025-05-26T15:59:57.426610Z","iopub.status.idle":"2025-05-26T15:59:57.441558Z","shell.execute_reply.started":"2025-05-26T15:59:57.426588Z","shell.execute_reply":"2025-05-26T15:59:57.440895Z"}},"outputs":[{"name":"stdout","text":"Tổng số dữ liệu: 2576\nSố lượng train: 2060\nSố lượng test: 516\n📄 Mẫu train:\n{'image_url': 'http://160.191.244.13:9000/lakehouse/imcp/augmented-data/2025-05-24/d62f86bc8aa3b964bb121d956af2f057_0.jpg', 'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'input_ids': tensor([[   0,  425,   13,  108,  415,  448, 7649,   15,   36,  981,    5, 1571,\n           10, 1214, 1784,    5,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n📄 Mẫu test:\n{'image_url': 'http://160.191.244.13:9000/lakehouse/imcp/augmented-data/2025-05-24/c647f4c03511dd23caa90772fe80f906_1.jpg', 'pixel_values': tensor([[[[-0.5686, -0.4824, -0.5922,  ..., -0.4431, -0.2784, -0.1608],\n          [-0.5373, -0.5451, -0.6235,  ..., -0.3882, -0.4196, -0.4353],\n          [-0.4431, -0.5922, -0.6392,  ..., -0.3804, -0.3961, -0.2549],\n          ...,\n          [ 0.1686,  0.1137,  0.0824,  ...,  0.0980,  0.1843,  0.1843],\n          [ 0.2549,  0.3176,  0.3255,  ...,  0.0667,  0.1294,  0.1294],\n          [ 0.5059,  0.6157,  0.5686,  ...,  0.0275,  0.0667,  0.0588]],\n\n         [[-0.4196, -0.2863, -0.3961,  ..., -0.3725, -0.1843, -0.0431],\n          [-0.3882, -0.3569, -0.4275,  ..., -0.2784, -0.3176, -0.3333],\n          [-0.3020, -0.4039, -0.4510,  ..., -0.2706, -0.3098, -0.1843],\n          ...,\n          [-0.0510, -0.0824, -0.0824,  ...,  0.0196,  0.1059,  0.1059],\n          [ 0.0745,  0.1529,  0.1843,  ..., -0.0039,  0.0588,  0.0510],\n          [ 0.3725,  0.4902,  0.4510,  ..., -0.0353, -0.0039, -0.0196]],\n\n         [[-0.6392, -0.5059, -0.5922,  ..., -0.5451, -0.3882, -0.3020],\n          [-0.6000, -0.5765, -0.6314,  ..., -0.5451, -0.5451, -0.5608],\n          [-0.4824, -0.6078, -0.6471,  ..., -0.5451, -0.5294, -0.3804],\n          ...,\n          [-0.2000, -0.2471, -0.2627,  ..., -0.1608, -0.0824, -0.0902],\n          [-0.0588, -0.0039,  0.0118,  ..., -0.1765, -0.1373, -0.1451],\n          [ 0.2471,  0.3255,  0.2627,  ..., -0.2078, -0.1922, -0.2157]]]]), 'input_ids': tensor([[   0, 7069,  140, 1867, 2911,    4,  715,  448,  330,    5,   18,  452,\n         1263,  121,  981,   12,   58, 1500,    5,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from datetime import datetime\nimport pickle\n\nprint(type(test_pkl_data[0]))\n\n# Lấy ngày hiện tại theo định dạng dd_mm_yy\ntoday_str = datetime.now().strftime(\"%d_%m_%y\")\n\n# Tạo tên file có chứa ngày\ntest_pkl_filename = f\"{today_str}_test_pkl_data.pkl\"\n\n# Lưu file\nwith open(test_pkl_filename, \"wb\") as f:\n    pickle.dump(test_pkl_data, f)\n\nprint(f\"✅ Đã lưu file test: '{test_pkl_filename}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:01:59.578586Z","iopub.execute_input":"2025-05-26T16:01:59.578948Z","iopub.status.idle":"2025-05-26T16:02:00.626339Z","shell.execute_reply.started":"2025-05-26T16:01:59.578924Z","shell.execute_reply":"2025-05-26T16:02:00.625119Z"}},"outputs":[{"name":"stdout","text":"<class 'dict'>\n✅ Đã lưu file test: '26_05_25_test_pkl_data.pkl'\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Colected Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef load_data(data_path=\"/kaggle/input/traffic-pictures-captioning/augmented/captions_augmented.csv\"):\n    try:\n        df = pd.read_csv(data_path)\n        df = df[['original_url','local_path', 'search_query', 'short_caption']].rename(columns={\n            'original_url': 'original_url',\n            'local_path': 'url',\n            'search_query': 'search_query',\n            'short_caption': 'caption'\n        })\n        print(f\"Đã tải CSV từ: {data_path} (Kích thước: {df.shape})\")\n        return df\n    except FileNotFoundError:\n        print(f\"Lỗi: Không tìm thấy file CSV tại {data_path}\")\n        raise\n    except Exception as e:\n        print(f\"Lỗi khi đọc CSV: {e}\")\n        raise\n\n# Load dữ liệu\ndf = load_data()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.019570Z","iopub.execute_input":"2025-05-26T09:02:09.019825Z","iopub.status.idle":"2025-05-26T09:02:09.324624Z","shell.execute_reply.started":"2025-05-26T09:02:09.019786Z","shell.execute_reply":"2025-05-26T09:02:09.323859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Split data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# Hàm chia dữ liệu giữ nguyên\ndef split_data(df, stratify_col='search_query', test_size=0.1, val_size=0.1, random_state=42):\n    unique_urls = df.drop_duplicates('original_url')\n\n    sss_1 = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n    for train_val_idx, test_idx in sss_1.split(unique_urls, unique_urls[stratify_col]):\n        train_val_urls = unique_urls.iloc[train_val_idx]['original_url']\n        test_urls = unique_urls.iloc[test_idx]['original_url']\n\n    df_train_val = df[df['original_url'].isin(train_val_urls)]\n    df_test = df[df['original_url'].isin(test_urls)]\n\n    unique_train_val_urls = df_train_val.drop_duplicates('original_url')\n    val_ratio = val_size / (1 - test_size)\n    sss_2 = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=random_state)\n    for train_idx, val_idx in sss_2.split(unique_train_val_urls, unique_train_val_urls[stratify_col]):\n        train_urls = unique_train_val_urls.iloc[train_idx]['original_url']\n        val_urls = unique_train_val_urls.iloc[val_idx]['original_url']\n\n    df_train = df_train_val[df_train_val['original_url'].isin(train_urls)]\n    df_val = df_train_val[df_train_val['original_url'].isin(val_urls)]\n\n    return df_train.reset_index(drop=True), df_val.reset_index(drop=True), df_test.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.325361Z","iopub.execute_input":"2025-05-26T09:02:09.325566Z","iopub.status.idle":"2025-05-26T09:02:09.332105Z","shell.execute_reply.started":"2025-05-26T09:02:09.325548Z","shell.execute_reply":"2025-05-26T09:02:09.331368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_split_save(df: pd.DataFrame): \n    # Split\n    train_df, val_df, test_df = split_data(df, stratify_col='search_query')\n    \n    # Kiểm tra\n    print(\"Train size:\", len(train_df))\n    print(\"Val size:\", len(val_df))\n    print(\"Test size:\", len(test_df))\n    print(train_df['search_query'].value_counts(normalize=True))\n    print(val_df['search_query'].value_counts(normalize=True))\n    print(test_df['search_query'].value_counts(normalize=True))\n\n    # Save file\n    # Reset index\n    train_df = train_df.reset_index(drop=True)\n    val_df = val_df.reset_index(drop=True)\n    test_df = test_df.reset_index(drop=True)\n    \n    # Kiểm tra số lượng mẫu sau khi chia\n    print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n    \n    # Lưu các DataFrame vào JSON\n    train_df.to_json(\"train.json\", orient='records', indent=4, force_ascii=False)\n    val_df.to_json(\"val.json\", orient='records', indent=4, force_ascii=False)\n    test_df.to_json(\"test.json\", orient='records', indent=4, force_ascii=False)\n    \n    print(\"Đã lưu train.json, val.json, test.json\")\n    return train_df, val_df, test_df, df\n\n# train_df, val_df, test_df, df = load_split_save(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.332873Z","iopub.execute_input":"2025-05-26T09:02:09.333105Z","iopub.status.idle":"2025-05-26T09:02:09.353283Z","shell.execute_reply.started":"2025-05-26T09:02:09.333081Z","shell.execute_reply":"2025-05-26T09:02:09.352681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Concat 2 data frame (colected + userAPI)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Giả sử df là DataFrame chứa cột ảnh hoặc thông tin ảnh\n# Bước 1: Chia train và tạm (val + test)\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n\n# Bước 2: Chia tiếp temp thành val và test\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, shuffle=True)\n\nprint(f\"Số lượng ảnh trong train: {len(train_df)}\")\nprint(f\"Số lượng ảnh trong val: {len(val_df)}\")\nprint(f\"Số lượng ảnh trong test: {len(test_df)}\")\n\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\ndf = df.copy().reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.353969Z","iopub.execute_input":"2025-05-26T09:02:09.354155Z","iopub.status.idle":"2025-05-26T09:02:09.388520Z","shell.execute_reply.started":"2025-05-26T09:02:09.354120Z","shell.execute_reply":"2025-05-26T09:02:09.387878Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Load feature extractor","metadata":{}},{"cell_type":"code","source":"feature_extractor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n\ndef load_image(local_path, dataset_base_path=\"/kaggle/input/traffic-pictures-captioning/\"):\n    \"\"\"\n    Load ảnh từ local_path trong dataset trên Kaggle.\n    \n    Parameters:\n    - local_path (str): Đường dẫn tương đối của ảnh (từ cột 'url' trong DataFrame)\n    - dataset_base_path (str): Đường dẫn gốc đến dataset\n    \n    Returns:\n    - image_rgb (numpy.ndarray): Ảnh ở định dạng RGB, hoặc None nếu lỗi\n    \"\"\"\n    try:\n        # Chuẩn hóa đường dẫn ảnh\n        local_path = local_path.lstrip('./')  # Loại bỏ './' nếu có\n        full_image_path = os.path.join(dataset_base_path, local_path)\n        \n        # Đọc ảnh bằng OpenCV\n        image = cv2.imread(full_image_path)\n        if image is None:\n            print(f\"Lỗi: Không thể đọc ảnh từ {full_image_path}\")\n            return None\n        \n        # Chuyển từ BGR sang RGB\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        return image_rgb\n    \n    except Exception as e:\n        print(f\"Lỗi khi xử lý ảnh {full_image_path}: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.394346Z","iopub.execute_input":"2025-05-26T09:02:09.395350Z","iopub.status.idle":"2025-05-26T09:02:09.524823Z","shell.execute_reply.started":"2025-05-26T09:02:09.395332Z","shell.execute_reply":"2025-05-26T09:02:09.524093Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Load Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load tokenizer của BartPho\n# tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-syllable\")\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\")\n\n# Kiểm tra vocab size\nvocab_size = tokenizer.vocab_size\nprint(f\"VOCAB SIZE: {vocab_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.529979Z","iopub.execute_input":"2025-05-26T09:02:09.530207Z","iopub.status.idle":"2025-05-26T09:02:09.951611Z","shell.execute_reply.started":"2025-05-26T09:02:09.530191Z","shell.execute_reply":"2025-05-26T09:02:09.950958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In ra các special tokens\nprint(\"Special Tokens:\", tokenizer.special_tokens_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.952440Z","iopub.execute_input":"2025-05-26T09:02:09.953296Z","iopub.status.idle":"2025-05-26T09:02:09.957062Z","shell.execute_reply.started":"2025-05-26T09:02:09.953274Z","shell.execute_reply":"2025-05-26T09:02:09.956354Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Các hàm tiền xử lý caption","metadata":{}},{"cell_type":"code","source":"def clean_text(text: str) -> str:\n    return re.sub(r\"[^\\w\\s,!?.]\", \"\", text).strip()\n\ndef to_lowercase(text: str) -> str:\n    return text.lower()\n\ndef join_vietnamese_compounds(text: str) -> str:\n    return ViTokenizer.tokenize(text)\n\ndef caption_preprocess(text: str) -> str:\n    text = clean_text(text)\n    text = to_lowercase(text)\n    text = join_vietnamese_compounds(text)\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.957668Z","iopub.execute_input":"2025-05-26T09:02:09.957905Z","iopub.status.idle":"2025-05-26T09:02:09.976433Z","shell.execute_reply.started":"2025-05-26T09:02:09.957880Z","shell.execute_reply":"2025-05-26T09:02:09.975744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = caption_preprocess(\"Kiểm tra phân tách từ\")\n\n# Tách token\ntokens = tokenizer.tokenize(text)\n\n# Chuyển token thành ID\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\n\ntext = tokenizer.decode(token_ids, skip_special_tokens=True)\n# In kết quả\nprint(\"List Word (Tokenized):\", tokens)\nprint(\"List Token ID:\", token_ids)\nprint(\"Text:\", text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.977081Z","iopub.execute_input":"2025-05-26T09:02:09.977297Z","iopub.status.idle":"2025-05-26T09:02:09.993089Z","shell.execute_reply.started":"2025-05-26T09:02:09.977281Z","shell.execute_reply":"2025-05-26T09:02:09.992494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hàm tính số từ của một caption\ndef count_words(caption):\n    preprocessed_caption = caption_preprocess(caption)\n    tokens = tokenizer.tokenize(preprocessed_caption)\n    return len(tokens)\n\n# Áp dụng hàm cho toàn bộ dataframe\ndf['word_count'] = df['caption'].apply(count_words)\n\n# Lấy độ dài lớn nhất\nmax_length = df['word_count'].max()\n\n# In ra\nprint(f\"Độ dài caption dài nhất là: {max_length} từ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:09.993868Z","iopub.execute_input":"2025-05-26T09:02:09.994079Z","iopub.status.idle":"2025-05-26T09:02:32.036684Z","shell.execute_reply.started":"2025-05-26T09:02:09.994063Z","shell.execute_reply":"2025-05-26T09:02:32.035858Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Tiền xử lý input model","metadata":{}},{"cell_type":"code","source":"def process_data(image_url, caption):\n    try:\n        img_array = load_image(image_url)\n        if img_array is None:\n            return None\n        \n        pixel_values = feature_extractor(img_array, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n        caption = caption_preprocess(caption)\n        tokenized_caption = tokenizer(caption, padding=\"max_length\", max_length=max_length, truncation=True)\n        \n        return {\n            \"pixel_values\": pixel_values,\n            \"input_ids\": torch.tensor(tokenized_caption[\"input_ids\"]),\n            \"attention_mask\": torch.tensor(tokenized_caption[\"attention_mask\"])\n        }\n    except Exception as e:\n        print(f\"Error processing data: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.040154Z","iopub.execute_input":"2025-05-26T09:02:32.040386Z","iopub.status.idle":"2025-05-26T09:02:32.045564Z","shell.execute_reply.started":"2025-05-26T09:02:32.040368Z","shell.execute_reply":"2025-05-26T09:02:32.044768Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Tạo tập dữ liệu huấn luyện","metadata":{}},{"cell_type":"code","source":"class ImageCaptionDataset(Dataset):\n    def __init__(self, image_paths, captions):\n        self.image_paths = image_paths\n        self.captions = captions\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        data = process_data(self.image_paths[idx], self.captions[idx])\n        if data is None:\n            return self.__getitem__((idx + 1) % len(self))\n        return data\n\ndef custom_collate_fn(batch):\n    batch = [item for item in batch if item is not None]\n    return {\n        \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in batch]),\n        \"input_ids\": torch.stack([item[\"input_ids\"] for item in batch]),\n        \"attention_mask\": torch.stack([item[\"attention_mask\"] for item in batch])\n    }\n\ntrain_dataset = ImageCaptionDataset(train_df[\"url\"], train_df[\"caption\"])\nval_dataset = ImageCaptionDataset(val_df[\"url\"], val_df[\"caption\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.046314Z","iopub.execute_input":"2025-05-26T09:02:32.046523Z","iopub.status.idle":"2025-05-26T09:02:32.068635Z","shell.execute_reply.started":"2025-05-26T09:02:32.046507Z","shell.execute_reply":"2025-05-26T09:02:32.067750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_pkl_data))\nprint(train_pkl_data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.069672Z","iopub.execute_input":"2025-05-26T09:02:32.070321Z","iopub.status.idle":"2025-05-26T09:02:32.090524Z","shell.execute_reply.started":"2025-05-26T09:02:32.070292Z","shell.execute_reply":"2025-05-26T09:02:32.089861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_dataset))\nprint(train_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.091416Z","iopub.execute_input":"2025-05-26T09:02:32.091731Z","iopub.status.idle":"2025-05-26T09:02:32.118557Z","shell.execute_reply.started":"2025-05-26T09:02:32.091713Z","shell.execute_reply":"2025-05-26T09:02:32.117975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class tạo Dataset từ list các dict\nclass DatasetFromList(Dataset):\n    def __init__(self, data_list):\n        self.data_list = data_list\n\n    def __len__(self):\n        return len(self.data_list)\n\n    def __getitem__(self, idx):\n        return self.data_list[idx]\n\n# Hàm tạo DatasetFromList từ list dict\ndef dataset_from_list(data_list):\n    return DatasetFromList(data_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.119270Z","iopub.execute_input":"2025-05-26T09:02:32.119503Z","iopub.status.idle":"2025-05-26T09:02:32.124145Z","shell.execute_reply.started":"2025-05-26T09:02:32.119475Z","shell.execute_reply":"2025-05-26T09:02:32.123518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_data = []\n\nfor item in train_pkl_data:\n    if \"image_url\" in item:\n        del item[\"image_url\"]\n\n    if \"pixel_values\" in item:\n        item[\"pixel_values\"] = item[\"pixel_values\"].squeeze(0)\n    \n    # Xử lý input_ids và attention_mask: squeeze rồi pad/cắt\n    if \"input_ids\" in item and \"attention_mask\" in item:\n        input_ids = item[\"input_ids\"].squeeze(0)\n        attention_mask = item[\"attention_mask\"].squeeze(0)\n\n        # Chuyển tensor sang list để dễ xử lý\n        input_ids_list = input_ids.tolist()\n        attention_mask_list = attention_mask.tolist()\n\n        # Pad hoặc truncate cho input_ids\n        if len(input_ids_list) < max_length:\n            pad_length = max_length - len(input_ids_list)\n            input_ids_list += [1] * pad_length          # pad với 1 (token id padding)\n            attention_mask_list += [0] * pad_length     # pad mask bằng 0\n        else:\n            input_ids_list = input_ids_list[:max_length]\n            attention_mask_list = attention_mask_list[:max_length]\n\n        # Chuyển lại thành tensor\n        import torch\n        item[\"input_ids\"] = torch.tensor(input_ids_list)\n        item[\"attention_mask\"] = torch.tensor(attention_mask_list)\n\n    new_data.append(item)\n\n\ncleaned_dataset = dataset_from_list(new_data)\nprint(cleaned_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.124765Z","iopub.execute_input":"2025-05-26T09:02:32.124969Z","iopub.status.idle":"2025-05-26T09:02:32.148055Z","shell.execute_reply.started":"2025-05-26T09:02:32.124953Z","shell.execute_reply":"2025-05-26T09:02:32.147455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ghép dataset cho dữ liệu cũ và dữ liệu mới từ API","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\n\ntrain_dataset = ConcatDataset([cleaned_dataset, train_dataset])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.148959Z","iopub.execute_input":"2025-05-26T09:02:32.149775Z","iopub.status.idle":"2025-05-26T09:02:32.156783Z","shell.execute_reply.started":"2025-05-26T09:02:32.149747Z","shell.execute_reply":"2025-05-26T09:02:32.155986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_dataset))\nprint(train_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:02:32.157573Z","iopub.execute_input":"2025-05-26T09:02:32.157773Z","iopub.status.idle":"2025-05-26T09:02:32.176337Z","shell.execute_reply.started":"2025-05-26T09:02:32.157756Z","shell.execute_reply":"2025-05-26T09:02:32.175686Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Cấu hình LoRA","metadata":{}},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig, TaskType\nfrom peft import PeftModel\n\n# Cấu hình LoRA\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"c_attn\", \"c_proj\"],  # Các lớp trong GPT2\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:15:59.567851Z","iopub.execute_input":"2025-05-26T08:15:59.568096Z","iopub.status.idle":"2025-05-26T08:15:59.881716Z","shell.execute_reply.started":"2025-05-26T08:15:59.568074Z","shell.execute_reply":"2025-05-26T08:15:59.881153Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10. Định nghĩa mô hình","metadata":{}},{"cell_type":"code","source":"vit_model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\ndel vit_model.classifier\nvit_model.vit.pooler = torch.nn.Sequential(OrderedDict([\n    ('dense', torch.nn.Linear(in_features=768, out_features=768, bias=True)),\n    ('activation', torch.nn.Tanh())\n]))\n\nconfig = GPT2Config.from_pretrained(\"gpt2\")\nconfig.add_cross_attention = True\nconfig.vocab_size = vocab_size\n\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config, ignore_mismatched_sizes=True)\ngpt2_model.resize_token_embeddings(config.vocab_size)\n\n# Áp dụng LoRA vào GPT2\ngpt2_model = get_peft_model(gpt2_model, lora_config)\ngpt2_model.print_trainable_parameters()  # kiểm tra số lượng tham số cần huấn luyện\n\nmodel = VisionEncoderDecoderModel(encoder=vit_model.vit, decoder=gpt2_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:15:59.882439Z","iopub.execute_input":"2025-05-26T08:15:59.882875Z","iopub.status.idle":"2025-05-26T08:16:07.036888Z","shell.execute_reply.started":"2025-05-26T08:15:59.882850Z","shell.execute_reply":"2025-05-26T08:16:07.036246Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 11. Định nghĩa lớp mô hình","metadata":{}},{"cell_type":"code","source":"class LoRACaptionWrapper(mlflow.pyfunc.PythonModel):\n    def __init__(self):\n        super().__init__()\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    def load_context(self, context):\n        try:\n            # Đường dẫn đầy đủ đến các thư mục con trong artifact\n            model_path = context.artifacts[\"model_dir\"]\n            tokenizer_path = os.path.join(model_path, \"tokenizer\")\n            feature_extractor_path = os.path.join(model_path, \"feature_extractor\")\n\n            \n            # Load các thành phần với đường dẫn chính xác\n            self.model = VisionEncoderDecoderModel.from_pretrained(model_path).to(self.device)\n            self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n            self.feature_extractor = ViTImageProcessor.from_pretrained(feature_extractor_path)\n            \n            # Đặt model vào chế độ eval\n            self.model.eval()\n        except Exception as e:\n            raise ValueError(f\"Error loading model: {str(e)}\")\n\n    def predict(self, context, model_input):\n        try:\n            # Xử lý đầu vào\n            if isinstance(model_input, dict):\n                image_url = model_input[\"url\"][0] if \"url\" in model_input else model_input[\"image_path\"][0]\n            else:\n                image_url = model_input.iloc[0][\"url\"] if \"url\" in model_input.columns else model_input.iloc[0][\"image_path\"]\n            \n            image = self.load_image(image_url)\n            if image is None:\n                return [\"\"]\n                \n            # Tiền xử lý ảnh và tạo caption\n            pixel_values = self.feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(self.device)\n            \n            output_ids = self.model.generate(\n                pixel_values,\n                max_length=45,\n                min_length=20,\n                num_beams=4,\n                do_sample=True,\n                temperature=0.8,\n                top_k=20,\n                top_p=0.9,\n                no_repeat_ngram_size=3,\n                repetition_penalty=2.0,\n                early_stopping=True,\n                pad_token_id=self.tokenizer.eos_token_id,\n                eos_token_id=self.tokenizer.eos_token_id,\n                decoder_start_token_id=self.tokenizer.bos_token_id\n            )\n            \n            caption = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n            return [caption.replace(\"_\", \" \").strip()]\n            \n        except Exception as e:\n            print(f\"[ERROR] during prediction: {e}\")\n            return [\"\"]\n   \n    def load_image(self, image_url):\n        try:\n            import requests\n            import numpy as np\n            from PIL import Image\n            from io import BytesIO\n            \n            response = requests.get(image_url, timeout=10)\n            if response.status_code != 200:\n                return None\n                \n            image = Image.open(BytesIO(response.content))\n            return image.convert(\"RGB\") if image else None\n            \n        except Exception as e:\n            print(f\"[ERROR] loading image: {e}\")\n            return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:16:07.037641Z","iopub.execute_input":"2025-05-26T08:16:07.037886Z","iopub.status.idle":"2025-05-26T08:16:07.117309Z","shell.execute_reply.started":"2025-05-26T08:16:07.037865Z","shell.execute_reply":"2025-05-26T08:16:07.116710Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 12. Huấn luyện mô hình","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\ndef evaluate_model(model, val_dataloader, device):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for batch in val_dataloader:\n            pixel_values = batch[\"pixel_values\"].to(device)\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n\n            encoder_outputs = model.encoder(pixel_values=pixel_values)\n            outputs = model.decoder(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                encoder_hidden_states=encoder_outputs.last_hidden_state,\n                labels=input_ids\n            )\n            loss = outputs.loss\n            total_loss += loss.item()\n    return total_loss / len(val_dataloader)\n\ndef train_model(model, train_dataloader, val_dataloader, tokenizer, feature_extractor, lr=5e-5, epochs=1, epoch_count=1, model_name='BartPho_ViT_GPT2_LoRA_ICG', data_part=\"Part_1\", df_log=None):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    # Optimizer chỉ update các tham số có requires_grad=True (LoRA adapter)\n    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    # Thống kê tham số trainable\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n\n    run_name = model_name + \"_\" + data_part\n\n    with mlflow.start_run(run_name=run_name):\n        if df_log is not None:\n            dataset = mlflow.data.from_pandas(df_log, targets=\"caption\")\n            mlflow.log_input(dataset, context=\"training\")\n\n        # Logging các siêu tham số\n        mlflow.log_param(\"epochs\", epochs)\n        mlflow.log_param(\"epoch_count\", epoch_count)\n        mlflow.log_param(\"data_part\", data_part)\n        mlflow.log_param(\"learning_rate\", lr)\n        mlflow.log_param(\"train_data_size\", len(train_dataloader.dataset))\n        mlflow.log_param(\"val_data_size\", len(val_dataloader.dataset))\n        mlflow.log_param(\"trainable_params\", trainable_params)\n        mlflow.log_param(\"total_params\", total_params)\n        mlflow.log_param(\"trainable_ratio\", round(trainable_params / total_params, 4))\n        mlflow.log_param(\"model_name\", model_name)\n\n        model.train()\n        for epoch in range(epochs):\n            total_loss = 0\n            for batch in train_dataloader:\n                pixel_values = batch[\"pixel_values\"].to(device)\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n\n                encoder_outputs = model.encoder(pixel_values=pixel_values)\n                outputs = model.decoder(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    encoder_hidden_states=encoder_outputs.last_hidden_state,\n                    labels=input_ids\n                )\n                loss = outputs.loss\n                total_loss += loss.item()\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n            avg_loss = total_loss / len(train_dataloader)\n            val_loss = evaluate_model(model, val_dataloader, device)\n\n            # Log loss theo epoch\n            mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n            print(f\"[Epoch {epoch+1}/{epochs}] Train Loss: {avg_loss:.4f} | Val Loss: {val_loss:.4f}\")\n\n            # Lưu mô hình sau mỗi epoch\n            epoch_save_path = f\"/kaggle/working/{model_name}_epoch_{epoch+1}\"\n            model.save_pretrained(epoch_save_path)\n            tokenizer.save_pretrained(os.path.join(epoch_save_path, \"tokenizer\"))\n            feature_extractor.save_pretrained(os.path.join(epoch_save_path, \"feature_extractor\"))\n            \n            # Log toàn bộ thư mục như một artifact\n            mlflow.log_artifacts(epoch_save_path, artifact_path=f\"epoch_{epoch+1}\")\n\n        # Lưu model cuối cùng riêng biệt\n        final_model_path = f\"/kaggle/working/{model_name}_final\"\n        model.save_pretrained(final_model_path)\n        tokenizer.save_pretrained(os.path.join(final_model_path, \"tokenizer\"))\n        feature_extractor.save_pretrained(os.path.join(final_model_path, \"feature_extractor\"))\n        mlflow.log_artifacts(final_model_path, artifact_path=\"final_model\")\n\n        # Log model dưới dạng pyfunc (nếu cần)\n        # Đảm bảo bạn đã định nghĩa class ImageCaptionModel trước\n\n        # Infer signature\n        input_example = pd.DataFrame({\"url\": [\"http://example.com/test.jpg\"]})\n        output_example = pd.DataFrame({\"caption\": [\"Mô tả ảnh\"]})\n        \n        # 2. Tạo model signature\n        signature = infer_signature(\n            input_example,\n            output_example,\n            params={\"input_types\": \"string\", \"output_types\": \"string\"}  # Chỉ định kiểu dữ liệu\n        )\n        mlflow.pyfunc.log_model(\n            artifact_path=\"model\",\n            python_model=LoRACaptionWrapper(),\n            artifacts={\"model_dir\": final_model_path},  # Đường dẫn đến thư mục chứa model, tokenizer và feature_extractor\n            registered_model_name=model_name,\n            signature=signature,\n            # input_example=input_example,\n            pip_requirements=pip_reqs\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:16:07.118074Z","iopub.execute_input":"2025-05-26T08:16:07.118730Z","iopub.status.idle":"2025-05-26T08:16:07.660264Z","shell.execute_reply.started":"2025-05-26T08:16:07.118701Z","shell.execute_reply":"2025-05-26T08:16:07.659723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo k Subset cho train, val\ntrain_subset = Subset(train_dataset, range(len(train_dataset)))  # Lấy train_df.shape[0] dữ liệu đầu tiên từ train_dataset\nval_subset = Subset(val_dataset, range(val_df.shape[0]))     # Lấy 4620 dữ liệu đầu tiên từ val_dataset\n\n# Tạo DataLoader cho các subset\ntrain_dataloader = DataLoader(train_subset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\nval_dataloader = DataLoader(val_subset, batch_size=4, shuffle=False, collate_fn=custom_collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:19:17.530669Z","iopub.execute_input":"2025-05-26T08:19:17.531368Z","iopub.status.idle":"2025-05-26T08:19:17.535627Z","shell.execute_reply.started":"2025-05-26T08:19:17.531341Z","shell.execute_reply":"2025-05-26T08:19:17.534894Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 13. Load model pretrain","metadata":{}},{"cell_type":"code","source":"# Đường dẫn thư mục chứa các tệp mô hình\nmodel_path = '/kaggle/input/phovit-gptcap/pytorch/default/15'\n\n# Tải mô hình VisionEncoderDecoder\nmodel = VisionEncoderDecoderModel.from_pretrained(model_path, ignore_mismatched_sizes=True)\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:19:21.450843Z","iopub.execute_input":"2025-05-26T08:19:21.451115Z","iopub.status.idle":"2025-05-26T08:19:22.252678Z","shell.execute_reply.started":"2025-05-26T08:19:21.451095Z","shell.execute_reply":"2025-05-26T08:19:22.252091Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 14. Huấn luyện","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\n# Lấy ngày hiện tại theo format dd-mm-yyyy\ntoday_str = datetime.now().strftime(\"%d-%m-%Y\")\nmodel_name = f'BartPho_ViT_GPT2_LoRA_ICG {today_str} Incremental'\n\ntrain_model(\n    model,\n    train_dataloader,\n    val_dataloader,\n    tokenizer,\n    feature_extractor,\n    lr=5e-5,\n    epochs=2,\n    epoch_count=17,\n    model_name=model_name,\n    data_part=\"FULL\",\n    df_log=df\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:20:21.053843Z","iopub.execute_input":"2025-05-26T08:20:21.054118Z","iopub.status.idle":"2025-05-26T08:20:29.532916Z","shell.execute_reply.started":"2025-05-26T08:20:21.054099Z","shell.execute_reply":"2025-05-26T08:20:29.531726Z"}},"outputs":[],"execution_count":null}]}